{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from load_data.ipynb\n",
      "importing Jupyter notebook from G:\\GitHub\\jupyter_test\\ABCNN\\abcnn\\basic.ipynb\n",
      "importing Jupyter notebook from G:\\GitHub\\jupyter_test\\ABCNN\\abcnn\\attentive_pooling.ipynb\n",
      "importing Jupyter notebook from G:\\GitHub\\jupyter_test\\ABCNN\\abcnn\\abcnn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import import_ipynb\n",
    "from load_data import QA_Preprocessor\n",
    "\n",
    "from abcnn import Basic_AP, Attentive_Pooling, Attentive_Pooling_1d, Attentive_Pooling_2d, ABCNN\n",
    "\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='ABCNN-implementation in pytorch')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA (default: False)')\n",
    "parser.add_argument('--eval', action='store_true',\n",
    "                    help='do evaluate (default: False)')\n",
    "parser.add_argument('--dropout', type=float, default=0,\n",
    "                    help='dropout applied to layers (default: 0)')\n",
    "parser.add_argument('--clip', type=float, default=-1,\n",
    "                    help='gradient clip, -1 means no clip (default: -1)')\n",
    "parser.add_argument('--epochs', type=int, default=15,\n",
    "                    help='upper epoch limit (default: 500)')\n",
    "parser.add_argument('--report_step', type=int, default=1, metavar='N',\n",
    "                    help='report interval (default: 20')\n",
    "parser.add_argument('--valid_step', type=int, default=1, metavar='N',\n",
    "                    help='validation interval (default: 20')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='initial learning rate (default: 1e-3)')\n",
    "parser.add_argument('--optim', type=str, default='Adam',\n",
    "                    help='optimizer to use (default: Adam)')\n",
    "parser.add_argument('--batchs', type=int, default=128,\n",
    "                    help='number of batchs (default: 10)')\n",
    "parser.add_argument('--val_batchs', type=int, default=32,\n",
    "                    help='number of batchs (default: 10)')\n",
    "parser.add_argument('--train_data', type=str, default='data/WikiQACorpus/WikiQA.train',\n",
    "                    help='the train dataset to run (default: data/WikiQACorpus/WikiQA-train.txt)')\n",
    "parser.add_argument('--dev_data', type=str, default='data/WikiQACorpus/WikiQA.dev',\n",
    "                    help='the dataset to run')\n",
    "parser.add_argument('--test_data', type=str, default='data/WikiQACorpus/WikiQA.test',\n",
    "                    help='the dataset to run (default: WikiQA)')\n",
    "parser.add_argument('--seed', type=int, default=190330,\n",
    "                    help='random seed (default: 190330)')\n",
    "parser.add_argument('--model_name', type=str, default='AP',\n",
    "                    help='the dataset to run (default: )')\n",
    "parser.add_argument('--filter_width', type=int, default=3,\n",
    "                    help='width of all filters (default: 4)')\n",
    "parser.add_argument('--num_layer', type=int, default=1,\n",
    "                    help='number of layers (default: 1)')\n",
    "parser.add_argument('--embedding_size', type=int, default=300,\n",
    "                    help='dimension of embeddings (default: 5)')\n",
    "parser.add_argument('--max_length', type=int, default=40,\n",
    "                    help='maximum of tokens for each sentence (default: 40)')\n",
    "\n",
    "args = parser.parse_args(['--cuda', '--eval', '--model_name', 'AP2d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchs=128, clip=-1, cuda=True, dev_data='data/WikiQACorpus/WikiQA.dev', dropout=0, embedding_size=300, epochs=15, eval=True, filter_width=3, lr=0.001, max_length=40, model_name='AP2d', num_layer=1, optim='Adam', report_step=1, seed=190330, test_data='data/WikiQACorpus/WikiQA.test', train_data='data/WikiQACorpus/WikiQA.train', val_batchs=32, valid_step=1)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: Please use a CUDA device. Run with --cuda\")\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-03 00:51:54.200763] Data_load done. Max token size: 409\n",
      "\tVocabulary size: 8869\n"
     ]
    }
   ],
   "source": [
    "data_preprocessor = QA_Preprocessor(args.train_data, length_limit=args.max_length)\n",
    "data = data_preprocessor.data\n",
    "Q_train = torch.tensor(data['q'], dtype=torch.long)\n",
    "A_train = torch.tensor(data['a'], dtype=torch.long)\n",
    "Y_train = torch.tensor(data['y'], dtype=torch.float)\n",
    "assert Q_train.shape[0] == A_train.shape[0] == Y_train.shape[0]\n",
    "#embeds = nn.Embedding(len_vocab, 5, padding_idx=0)\n",
    "#hello_embed = embeds(Q_train)\n",
    "\n",
    "data_preprocessor.reset_data()\n",
    "data_preprocessor.load_raw_file(args.dev_data)\n",
    "data = data_preprocessor.data\n",
    "Q_dev = torch.tensor(data['q'], dtype=torch.long)\n",
    "A_dev = torch.tensor(data['a'], dtype=torch.long)\n",
    "Y_dev = torch.tensor(data['y'], dtype=torch.float)\n",
    "\n",
    "Q_test = None\n",
    "A_test = None\n",
    "Y_test = None\n",
    "if args.eval:\n",
    "    data_preprocessor.reset_data()\n",
    "    data_preprocessor.load_raw_eval_file(args.test_data)\n",
    "    data = data_preprocessor.data\n",
    "    Q_test = data['q']\n",
    "    A_test = data['a']\n",
    "    Y_test = data['y']\n",
    "\n",
    "vocab_size = len(data_preprocessor.vocab)\n",
    "print('\\tVocabulary size:', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "if args.model_name == 'Basic_AP':\n",
    "    model = Basic_AP(vocab_size, args.embedding_size, args.max_length)\n",
    "elif args.model_name == 'AP':\n",
    "    model = Attentive_Pooling(vocab_size, args.embedding_size, args.max_length, kernel_size=args.filter_width)\n",
    "elif args.model_name == 'AP1d':\n",
    "    model = Attentive_Pooling_1d(vocab_size, args.embedding_size, args.max_length, \n",
    "                                 kernel_size=args.filter_width)\n",
    "elif args.model_name == 'AP2d':\n",
    "    model = Attentive_Pooling_2d(vocab_size, args.embedding_size, args.max_length, \n",
    "                                 kernel_size=args.filter_width)\n",
    "elif args.model_name == 'ABCNN':\n",
    "    model = ABCNN(vocab_size, args.embedding_size, args.max_length, \n",
    "                                 kernel_size=args.filter_width)\n",
    "else:\n",
    "    print('No such model name')\n",
    "    exit()\n",
    "    \n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = None\n",
    "if args.optim == 'Adam' or args.optim == 'RMSprop':\n",
    "    optimizer = getattr(optim, args.optim)(model.parameters(), lr=args.lr)\n",
    "    \n",
    "#criterion = nn.CosineEmbeddingLoss(margin=0.1)\n",
    "criterion = nn.BCELoss(reduction='sum')\n",
    "#criterion = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_q = Q_train[:2].cuda()\n",
    "x_a = A_train[:2].cuda()\n",
    "model.forward(x_q, x_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_index(total_length, batch_size, do_shuffle = True):\n",
    "    train_idx_list = np.arange(total_length)\n",
    "    if do_shuffle:\n",
    "        np.random.shuffle(train_idx_list)\n",
    "    batch_indices = []\n",
    "    for i in range((total_length // batch_size)+1):\n",
    "        start_idx = i*batch_size\n",
    "        end_idx = min(total_length, (i+1)*batch_size)\n",
    "        if start_idx == end_idx:\n",
    "            break\n",
    "        sub_indices = train_idx_list[start_idx : end_idx]\n",
    "        batch_indices.append(sub_indices)\n",
    "    return batch_indices\n",
    "\n",
    "def train_per_epoch(batch_size):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    count = len(Q_train)\n",
    "    batch_indices = generate_batch_index(count, batch_size)\n",
    "    for idx_list in batch_indices:\n",
    "        x_q = Variable(Q_train[idx_list])\n",
    "        x_a = Variable(A_train[idx_list])\n",
    "        y = Variable(Y_train[idx_list])\n",
    "        if args.cuda:\n",
    "            x_q, x_a, y = x_q.cuda(), x_a.cuda(), y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x_q, x_a)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        total_loss += loss.item() /count\n",
    "        if args.clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Q_test, A_test, Y_test):\n",
    "    model.eval()\n",
    "    mean_avg_precision = 0\n",
    "    mean_rr = 0\n",
    "    num_q = len(Q_test)\n",
    "    with torch.no_grad():\n",
    "        for test_step in range(num_q):\n",
    "            x_q = torch.tensor(Q_test[test_step], dtype=torch.long)\n",
    "            x_q = Variable(x_q)\n",
    "            x_a = torch.tensor(A_test[test_step], dtype=torch.long)\n",
    "            x_a = Variable(x_a)\n",
    "            y = torch.tensor(Y_test[test_step], dtype=torch.long)\n",
    "            y = Variable(y)\n",
    "            if args.cuda:\n",
    "                x_q, x_a = x_q.cuda(), x_a.cuda()\n",
    "            output = model(x_q, x_a)\n",
    "            output = output.cpu()\n",
    "            if torch.sum(torch.isnan(output)) > 0:\n",
    "                print('output error on evaluation')\n",
    "                exit()\n",
    "            add_mrr = True\n",
    "            num_rel = 0\n",
    "            avg_pre = 0\n",
    "            for rank, idx in enumerate(np.argsort(-output, axis=0)):                \n",
    "                if y[idx] == 1:\n",
    "                    #MRR\n",
    "                    if add_mrr:\n",
    "                        mean_rr += 1/(rank+1)\n",
    "                        add_mrr = False\n",
    "                    #MAP\n",
    "                    num_rel += 1\n",
    "                    avg_pre += num_rel / (rank+1)\n",
    "            if num_rel > 0:\n",
    "                avg_pre = avg_pre / num_rel\n",
    "            mean_avg_precision += avg_pre\n",
    "    mean_rr = mean_rr / num_q\n",
    "    mean_avg_precision = mean_avg_precision / num_q\n",
    "    return mean_avg_precision, mean_rr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(batch_size):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    count = len(Q_dev)\n",
    "    batch_indices = generate_batch_index(count, batch_size, do_shuffle = False)\n",
    "    with torch.no_grad():\n",
    "        for idx_list in batch_indices:\n",
    "            x_q = Variable(Q_dev[idx_list])\n",
    "            x_a = Variable(A_dev[idx_list])\n",
    "            y = Variable(Y_dev[idx_list])\n",
    "            if args.cuda:\n",
    "                x_q, x_a, y = x_q.cuda(), x_a.cuda(), y.cuda()\n",
    "            output = model(x_q, x_a)\n",
    "            loss = criterion(output, y)\n",
    "            total_loss += loss.item() \n",
    "        eval_loss = total_loss / count\n",
    "        return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-04-03 00:51:56.154125] model: <AP2d>; lr: <0.00100>; optimizer: <Adam>\n",
      "[2019-04-03 00:52:09.038004] Step  1/15; loss: 0.20630; 12.9s \n",
      "\t Validation loss 0.19965 \n",
      "[2019-04-03 00:52:21.154130] Step  2/15; loss: 0.19629; 25.0s \n",
      "\t Validation loss 0.19522 \n",
      "[2019-04-03 00:52:33.194279] Step  3/15; loss: 0.18961; 37.0s \n",
      "\t Validation loss 0.19087 \n",
      "[2019-04-03 00:52:45.232429] Step  4/15; loss: 0.17896; 49.1s \n",
      "\t Validation loss 0.18431 \n",
      "[2019-04-03 00:52:57.282575] Step  5/15; loss: 0.16760; 61.1s \n",
      "\t Validation loss 0.18121 \n",
      "[2019-04-03 00:53:09.329722] Step  6/15; loss: 0.15567; 73.2s \n",
      "\t Validation loss 0.17984 \n",
      "[2019-04-03 00:53:21.422855] Step  7/15; loss: 0.14411; 85.3s \n",
      "\t Validation loss 0.18269 \n",
      "[2019-04-03 00:53:33.599960] Step  8/15; loss: 0.13297; 97.4s \n",
      "\t Validation loss 0.18321 \n",
      "[2019-04-03 00:53:45.636111] Step  9/15; loss: 0.12230; 109.5s \n",
      "\t Validation loss 0.18791 \n",
      "[2019-04-03 00:53:57.720246] Step 10/15; loss: 0.11230; 121.6s \n",
      "\t Validation loss 0.19154 \n",
      "[2019-04-03 00:54:09.846368] Step 11/15; loss: 0.10272; 133.7s \n",
      "\t Validation loss 0.19717 \n",
      "[2019-04-03 00:54:21.886517] Step 12/15; loss: 0.09458; 145.7s \n",
      "\t Validation loss 0.20353 \n",
      "[2019-04-03 00:54:33.917669] Step 13/15; loss: 0.08697; 157.8s \n",
      "\t Validation loss 0.21504 \n",
      "[2019-04-03 00:54:45.958819] Step 14/15; loss: 0.08061; 169.8s \n",
      "\t Validation loss 0.21796 \n",
      "[2019-04-03 00:54:58.004970] Step 15/15; loss: 0.07429; 181.9s \n",
      "\t Validation loss 0.22624 \n",
      "--------------------------------------------------------------------------------\n",
      "Best performance: 0.17984\n",
      "Evaluation- MAP: 0.70714, MRR: 0.71854\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    best_vloss = None\n",
    "    model_file = \"./save/{0}.pt\".format(args.model_name)\n",
    "    start_time = datetime.now()\n",
    "    print(\"[{:s}] model: <{:s}>; lr: <{:.5f}>; optimizer: <{:s}>\".format(\n",
    "        str(start_time), args.model_name, args.lr, args.optim))\n",
    "    for ep in range(1, args.epochs+1):\n",
    "        rloss = train_per_epoch(args.batchs)       \n",
    "        \n",
    "        if ep % args.report_step == 0:\n",
    "            now = datetime.now()\n",
    "            dist_time = now - start_time            \n",
    "            print(\"[{:s}] Step {:2d}/{:2d}; loss: {:.5f}; {:.1f}s \".format(str(now), \n",
    "                                                                           ep, \n",
    "                                                                           args.epochs, \n",
    "                                                                           rloss, \n",
    "                                                                           dist_time.total_seconds()))\n",
    "\n",
    "        if ep % args.valid_step == 0:\n",
    "            vloss = validate(args.val_batchs)\n",
    "            print(\"\\t Validation loss {:.5f} \".format(vloss))\n",
    "            if (best_vloss == None) or vloss < best_vloss:\n",
    "                torch.save({'state_dict': model.state_dict()}, model_file)\n",
    "                best_vloss = vloss\n",
    "    print('-' * 80)\n",
    "    checkpoint = torch.load(model_file)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    \n",
    "    best_vloss = validate(args.val_batchs)\n",
    "    print('Best performance: {:.5f}'.format(best_vloss))    \n",
    "    if args.eval:\n",
    "        mAP_score, mrr_score = evaluate(Q_test, A_test, Y_test)\n",
    "        print('Evaluation- MAP: {:.5f}, MRR: {:.5f}'.format(mAP_score, mrr_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
