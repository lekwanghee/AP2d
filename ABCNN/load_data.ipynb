{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class QA_Preprocessor():\n",
    "    def __init__(self, file_path, length_limit = 40):\n",
    "        self.file_path = file_path\n",
    "        self.max_token = 0\n",
    "        self.vocab = {}\n",
    "        self.data = {'q': [], 'a': [], 'y': []}\n",
    "        self.data_dict = {'q': {}, 'a': {}}\n",
    "        self.length_limit = length_limit\n",
    "        self.load_raw_file(file_path)\n",
    "        now = datetime.now()\n",
    "        print('[{:s}] Data_load done. Max token size: {:d}'.format(str(now), self.max_token))\n",
    "                \n",
    "    def load_raw_file(self, file_path):\n",
    "        f = open(file_path, 'r', encoding='utf8')\n",
    "        for line in f:\n",
    "            str_split = line.lower().split('\\t')\n",
    "            y_value = int(''.join(i for i in str_split[2] if i.isdigit())) #if int(str_split[2])>0 else -1\n",
    "            self.data['y'].append(y_value)\n",
    "            for i, value in enumerate(['q', 'a']):\n",
    "                sent = str_split[i]\n",
    "                if not (sent in self.data_dict[value]):\n",
    "                    split_sent = sent.split()\n",
    "                    bow_sent = [0]*self.length_limit\n",
    "                    if self.max_token < len(split_sent):\n",
    "                        self.max_token = len(split_sent)\n",
    "                    for idx, word in enumerate(split_sent):\n",
    "                        if idx >= self.length_limit:\n",
    "                            break\n",
    "                        word_idx = 0\n",
    "                        if not(word in self.vocab):\n",
    "                            self.vocab[word] = len(self.vocab)+1\n",
    "                        word_idx = self.vocab[word]\n",
    "                        bow_sent[idx] = word_idx\n",
    "                    self.data_dict[value][sent] = bow_sent\n",
    "                bow_sent = self.data_dict[value][sent][:]\n",
    "                self.data[value]+= bow_sent\n",
    "        #Make a form of datasets to (-1, 40)\n",
    "        for i, value in enumerate(['q', 'a']):\n",
    "            self.data[value] = np.array(self.data[value]).reshape((-1, self.length_limit))\n",
    "        #Make a form of binary labels to (-1, 1)\n",
    "        self.data['y'] = np.array(self.data['y']).reshape((-1, 1))\n",
    "        \n",
    "    def load_raw_eval_file(self, file_path):\n",
    "        f = open(file_path, 'r', encoding='utf8')\n",
    "        len_cnt = 0 #tbd\n",
    "        is_save = False\n",
    "        y_list = []\n",
    "        data_list = {'q': [], 'a': []}\n",
    "        \n",
    "        for line in f:\n",
    "            str_split = line.lower().split('\\t')\n",
    "            for i, value in enumerate(['q', 'a']):\n",
    "                sent = str_split[i]\n",
    "                if not (sent in self.data_dict[value]):\n",
    "                    if value == 'q':\n",
    "                        if is_save:\n",
    "                            y_list = np.array(y_list).reshape((-1, 1))\n",
    "                            self.data['y'].append(y_list)\n",
    "                            for key in ['q', 'a']:\n",
    "                                data_list[key] = np.array(data_list[key]).reshape((-1, self.length_limit))\n",
    "                                self.data[key].append(data_list[key])\n",
    "\n",
    "                        is_save = False\n",
    "                        y_list = []\n",
    "                        data_list = {'q': [], 'a': []}\n",
    "                        \n",
    "                    split_sent = sent.split()\n",
    "                    bow_sent = [0]*self.length_limit\n",
    "                    for idx, word in enumerate(split_sent):\n",
    "                        if idx >= self.length_limit:\n",
    "                            break\n",
    "                        word_idx = 0\n",
    "                        if not(word in self.vocab):\n",
    "                            self.vocab[word] = len(self.vocab)+1\n",
    "                        word_idx = self.vocab[word]\n",
    "                        bow_sent[idx] = word_idx\n",
    "                    self.data_dict[value][sent] = bow_sent\n",
    "                bow_sent = self.data_dict[value][sent][:]\n",
    "                data_list[value]+= bow_sent\n",
    "            y_value = int(''.join(i for i in str_split[2] if i.isdigit())) #if int(str_split[2])>0 else -1\n",
    "            if y_value == 1:\n",
    "                is_save = True\n",
    "            y_list.append(y_value)\n",
    "   \n",
    "        \n",
    "    def reset_data(self):\n",
    "        self.data = {'q': [], 'a': [], 'y': []}\n",
    "        self.data_dict = {'q': {}, 'a': {}}\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
